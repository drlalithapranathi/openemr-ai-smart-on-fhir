name: RAG Medical Summarization (All Patients)

on:
  workflow_dispatch:
    inputs:
      run_llama_3_1_8b:
        description: 'Run Llama 3.1 8B model'
        type: boolean
        default: true
      run_medgemma_4b:
        description: 'Run MedGemma 4B-IT model'
        type: boolean
        default: true
      run_medgemma_27b_4bit:
        description: 'Run MedGemma 27B-Text-IT (4-bit) model'
        type: boolean
        default: true
      run_gpt_oss_20b:
        description: 'Run Groq GPT-OSS-20B model'
        type: boolean
        default: true
      run_gpt_oss_120b:
        description: 'Run Groq GPT-OSS-120B model'
        type: boolean
        default: true
      run_qwen3_32b:
        description: 'Run Groq Qwen3-32B model'
        type: boolean
        default: true
      run_llama4_scout:
        description: 'Run Groq Llama-4-Scout-17B model'
        type: boolean
        default: true
  push:
    paths:
      - 'pranathi_RAG/**'
      - 'rag_models/RAG_To_See_MedGemma_Performance/**'
      - '.github/workflows/rag-summarization.yml'

env:
  PYTHON_VERSION: '3.11'

jobs:
  # ============================================
  # JOB 1: Llama 3.1 8B RAG Summarization
  # File: pranathi_RAG/main.py
  # ============================================
  llama-3-1-8b:
    name: ðŸ¦™ Llama 3.1 8B (All Patients)
    if: github.event.inputs.run_llama_3_1_8b != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Copy summary_utils.py to pranathi_RAG
        run: |
          cp rag_models/RAG_To_See_MedGemma_Performance/summary_utils.py pranathi_RAG/

      - name: Run Llama 3.1 8B Pipeline
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd pranathi_RAG
          echo "ðŸš€ Running Llama 3.1 8B summarization for ALL patients from Notion"
          modal run main.py --output-dir results/llama-3.1-8b

      - name: Display Results Summary
        run: |
          RESULTS_DIR="pranathi_RAG/results/llama-3.1-8b"
          
          echo "## ðŸ¦™ Llama 3.1 8B Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_llama-3.1-8b.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_llama-3.1-8b.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: llama-3.1-8b-results
          path: pranathi_RAG/results/llama-3.1-8b/
          retention-days: 90

  # ============================================
  # JOB 2: MedGemma 4B-IT RAG Summarization
  # File: rag_models/RAG_To_See_MedGemma_Performance/main_medgemma_4b_modal.py
  # ============================================
  medgemma-4b:
    name: ðŸ¥ MedGemma 4B-IT (All Patients)
    if: github.event.inputs.run_medgemma_4b != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Run MedGemma 4B-IT Pipeline
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          echo "ðŸš€ Running MedGemma 4B-IT summarization for ALL patients from Notion"
          modal run main_medgemma_4b_modal.py --output-dir results/medgemma-4b

      - name: Display Results Summary
        run: |
          RESULTS_DIR="rag_models/RAG_To_See_MedGemma_Performance/results/medgemma-4b"
          
          echo "## ðŸ¥ MedGemma 4B-IT Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_medgemma-4b.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_medgemma-4b.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: medgemma-4b-results
          path: rag_models/RAG_To_See_MedGemma_Performance/results/medgemma-4b/
          retention-days: 90

  # ============================================
  # JOB 3: MedGemma 27B-Text-IT (4-bit) RAG Summarization
  # File: rag_models/RAG_To_See_MedGemma_Performance/medgemma_27b_4bit_modal.py
  # ============================================
  medgemma-27b-4bit:
    name: ðŸ¥ MedGemma 27B (4-bit) (All Patients)
    if: github.event.inputs.run_medgemma_27b_4bit != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Run MedGemma 27B (4-bit) Pipeline
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          echo "ðŸš€ Running MedGemma 27B (4-bit) summarization for ALL patients from Notion"
          modal run medgemma_27b_4bit_modal.py --output-dir results/medgemma-27b-4bit

      - name: Display Results Summary
        run: |
          RESULTS_DIR="rag_models/RAG_To_See_MedGemma_Performance/results/medgemma-27b-4bit"
          
          echo "## ðŸ¥ MedGemma 27B (4-bit) Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_medgemma-27b-4bit.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_medgemma-27b-4bit.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: medgemma-27b-4bit-results
          path: rag_models/RAG_To_See_MedGemma_Performance/results/medgemma-27b-4bit/
          retention-days: 90

  # ============================================
  # JOB 4: Groq GPT-OSS-20B RAG Summarization
  # File: pranathi_RAG/main_groq.py
  # ============================================
  gpt-oss-20b:
    name: ðŸš€ Groq GPT-OSS-20B (All Patients)
    if: github.event.inputs.run_gpt_oss_20b != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Copy summary_utils.py to pranathi_RAG
        run: |
          cp rag_models/RAG_To_See_MedGemma_Performance/summary_utils.py pranathi_RAG/

      - name: Run Groq GPT-OSS-20B Pipeline
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd pranathi_RAG
          echo "ðŸš€ Running Groq GPT-OSS-20B summarization for ALL patients from Notion"
          modal run main_groq.py --output-dir results/gpt-oss-20b

      - name: Display Results Summary
        run: |
          RESULTS_DIR="pranathi_RAG/results/gpt-oss-20b"
          
          echo "## ðŸš€ Groq GPT-OSS-20B Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_gpt-oss-20b.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_gpt-oss-20b.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: gpt-oss-20b-results
          path: pranathi_RAG/results/gpt-oss-20b/
          retention-days: 90

  # ============================================
  # JOB 5: Groq GPT-OSS-120B RAG Summarization
  # File: rag_models/RAG_To_See_MedGemma_Performance/gpt_120b_modal.py
  # ============================================
  gpt-oss-120b:
    name: ðŸš€ Groq GPT-OSS-120B (All Patients)
    if: github.event.inputs.run_gpt_oss_120b != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Run Groq GPT-OSS-120B Pipeline
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          echo "ðŸš€ Running Groq GPT-OSS-120B summarization for ALL patients from Notion"
          modal run gpt_120b_modal.py --output-dir results/gpt-oss-120b

      - name: Display Results Summary
        run: |
          RESULTS_DIR="rag_models/RAG_To_See_MedGemma_Performance/results/gpt-oss-120b"
          
          echo "## ðŸš€ Groq GPT-OSS-120B Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_gpt-oss-120b.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_gpt-oss-120b.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: gpt-oss-120b-results
          path: rag_models/RAG_To_See_MedGemma_Performance/results/gpt-oss-120b/
          retention-days: 90

  # ============================================
  # JOB 6: Groq Qwen3-32B RAG Summarization
  # File: rag_models/RAG_To_See_MedGemma_Performance/qwen_32b_modal.py
  # ============================================
  qwen3-32b:
    name: ðŸ§  Groq Qwen3-32B (All Patients)
    if: github.event.inputs.run_qwen3_32b != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Run Groq Qwen3-32B Pipeline
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          echo "ðŸš€ Running Groq Qwen3-32B summarization for ALL patients from Notion"
          modal run qwen_32b_modal.py --output-dir results/qwen3-32b

      - name: Display Results Summary
        run: |
          RESULTS_DIR="rag_models/RAG_To_See_MedGemma_Performance/results/qwen3-32b"
          
          echo "## ðŸ§  Groq Qwen3-32B Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_qwen3-32b.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_qwen3-32b.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: qwen3-32b-results
          path: rag_models/RAG_To_See_MedGemma_Performance/results/qwen3-32b/
          retention-days: 90

  # ============================================
  # JOB 7: Groq Llama-4-Scout-17B RAG Summarization
  # File: rag_models/RAG_To_See_MedGemma_Performance/groq_llama_4_scout_modal.py
  # ============================================
  llama4-scout:
    name: ðŸ¦™ Groq Llama-4-Scout-17B (All Patients)
    if: github.event.inputs.run_llama4_scout != 'false'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install modal notion-client httpx pandas python-dotenv

      - name: Authenticate Modal
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
        run: |
          modal token set --token-id $MODAL_TOKEN_ID --token-secret $MODAL_TOKEN_SECRET

      - name: Run Groq Llama-4-Scout-17B Pipeline
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          VISHNU_NOTION: ${{ secrets.VISHNU_NOTION }}
          VISHNU_NOTION_DB_ID: ${{ secrets.VISHNU_NOTION_DB_ID }}
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          echo "ðŸš€ Running Groq Llama-4-Scout-17B summarization for ALL patients from Notion"
          modal run groq_llama_4_scout_modal.py --output-dir results/llama4-scout

      - name: Display Results Summary
        run: |
          RESULTS_DIR="rag_models/RAG_To_See_MedGemma_Performance/results/llama4-scout"
          
          echo "## ðŸ¦™ Groq Llama-4-Scout-17B Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "$RESULTS_DIR/evaluation_results_llama4-scout.csv" ]; then
            echo "### Evaluation Metrics" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat "$RESULTS_DIR/evaluation_results_llama4-scout.csv" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Results CSV not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: llama4-scout-results
          path: rag_models/RAG_To_See_MedGemma_Performance/results/llama4-scout/
          retention-days: 90

  # ============================================
  # JOB 8: Compare All Model Results
  # Uses: rag_models/RAG_To_See_MedGemma_Performance/summary_utils.py
  # ============================================
  compare-results:
    name: ðŸ“Š Compare All Models
    needs: [llama-3-1-8b, medgemma-4b, medgemma-27b-4bit, gpt-oss-20b, gpt-oss-120b, qwen3-32b, llama4-scout]
    if: always()
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install pandas notion-client httpx python-dotenv

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-results

      - name: Generate Consolidated Report
        run: |
          cd rag_models/RAG_To_See_MedGemma_Performance
          python summary_utils.py --report ../../all-results ../../all-results

      - name: Append to GitHub Summary
        run: |
          if [ -f "all-results/comparison_report.md" ]; then
            cat all-results/comparison_report.md >> $GITHUB_STEP_SUMMARY
          else
            echo "## âš ï¸ No comparison report generated" >> $GITHUB_STEP_SUMMARY
            echo "Some model jobs may have failed or been skipped." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload Consolidated Results
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-comparison
          path: |
            all-results/consolidated_results.csv
            all-results/model_comparison.csv
            all-results/comparison_report.md
          retention-days: 90